- [ ] IOU 的 [计算](https://github.com/faciallab/FaceDetector/blob/master/mtcnn/utils/nms/py_cpu_nms.py) 与理解：
    - 首先得算独立面积。并集=独立面积和-交集；
    - 交集面积=w*h，分别用两组x2/y2的最小值-两组x1/y1的最大值表示，并要注意取0的截断。
- [ ] NMS 的 [计算](https://github.com/faciallab/FaceDetector/blob/master/mtcnn/utils/nms/py_cpu_nms.py) 与理解
    -  对每个序号求一遍面积先（IOU 需要）
    -  置信度排序
    -  计算最高置信度，与剩下所有 bbox 的 IOU
    -  将小于 IOU 设定阈值的保留下来。
    -  指针下移，循环直到剩下待筛选的 bbox 为空。
- [ ] MTCNN 的训练 [邬继阳师兄代码](https://github.com/wujiyang/MTCNN_TRAIN)
    - 数据集：WiderFace 边框回归；Celeb-A 关键点回归。 
    - 分阶段训练：递进式，将前一层保留的模型用于样本生成；
    - 各阶段数据生成：正负样本采用三段式IOU阈值筛选；
    - Landmark 的只在 ONet 训练和调用。
- [ ] Focal Loss (RetinaNet)
- [ ] RetinaFace 的理解：单阶段的，尺度问题从图像金字塔到特征金字塔转换（必然引入Anchor策略），损失函数也有特殊设置，分类/回归/关键点+图卷积的方式，对人脸结构化建模。
    - [zhihu 解释](https://zhuanlan.zhihu.com/p/103005911)
    - 复现
      - 现成的检测+68关键点的模型：[link](https://github.com/ElvishElvis/68-Retinaface-Pytorch-version)
      - 很全的训练测试逻辑和数据集：[link](https://github.com/jerry4h/Pytorch_Retinaface)
      - 加入关键点的训练：[link](https://github.com/ElvishElvis/68-Retinaface-Pytorch-version)
        - 依赖 LS3D-W，想训练这个的话还是得用 FAN。
- [ ] Inverted Attention：自带对抗感觉
- [ ] Anchor Free（单尺度Anchor-关键点检测思路-分割思路）[link](https://zhuanlan.zhihu.com/p/62103812)
  - [ ] DenseBox：单 FCN，每个pixel 预测 BBOX+C（5个scalar）
  - [ ] YOLO：`S*S*(B*5+C)`
  - [ ] CornerNet：预测关键点Corner。
  - [ ] FCOS
  - [ ] FoveaBox
  - [ ] 后续：直接预测关键点。
  - [ ] FPN 的利用：解决语义模糊性问题，多尺度，利于小目标、大目标的检测，训练时选择优化head，推导时最适合的会给出最大值。。


## 关键点检测

- 人脸关键点检测 FAN [link](https://www.adrianbulat.com/face-alignment)
  - 可能还是当今较为可行的方法。
  - 当前最需要复现的方法吧。准确的关键点定位，速度慢可以接受吧