
## 统计

- [ ] 常见分布：[link](https://www.zhihu.com/question/50561130/answer/262339774)
  - 离散分布
    - 伯努利分布：两种可能性的概率分布（生孩子的性别）
    - 二项分布：多次伯努利，某事件的次数
    - 多项式分布
  - 连续分布
    - 高斯分布（方差处取平方）
    - 拉普拉斯分布（广度处取绝对值）
- [x] 条件概率分布 [link](https://zhuanlan.zhihu.com/p/26464206)
- [ ] 先验 / 后验概率：经过统计 / 观察某事件后得到的事件概率分布。
- [x] 先验 / 后验概率与极大似然估计：后验概率是知果求因，极大似然是知果求最可能的原因。[link](https://zhuanlan.zhihu.com/p/24423230)

## 矩阵论

- [ ] 矩阵的特征值与特征向量 [link](https://www.zhihu.com/question/21874816/answer/181864044)
  - $AM=\lambda M$ 
  - 特征值表示最快的变化速度，特征向量表示最快的变化方向

## 降维
  - 某些维度之间存在较强的线性相关关系
  - 误差重建最小化：用数据方差较小的高维向量表示映射的新基底
  - [ ] PCA：主成分分析 [link](https://mp.weixin.qq.com/s?__biz=MzU4MjQ3MDkwNA==&mid=2247484754&idx=1&sn=b2c0d6798f44e13956bb42373e51d18c&chksm=fdb698c5cac111d3e3dca24c50aafbfb61e5b05c5df5b603067bb7edec8db049370b73046b24&scene=21#wechat_redirect)
    1. 把每一条数据当一个行向量，让数据集中的各个行向量堆叠成一个矩阵。
    2. 将数据集的每一个维度上的数据减去这个维度的均值，使数据集每个维度的均值都变成 0，得到矩阵 X。
    3. 计算方阵 $X^TX$ 的特征值和特征向量，将特征向量按照特征值由大到小的顺序从左到右组合成一个变化矩阵 W。为了降低数据维度，我们可以将特征值较小的特征向量丢弃。
    4. 计算 $T = XW$，这里的 T 就是经过 PCA 之后的数据矩阵。

## 概率图模型
- **高维随机变量**：$p(x_1, x_2,..., x_p)$  
  - 边缘概率 $p(x_p)$
  - 条件概率 $p(x_j|x_i)$
- **计算规则**
  - Sum Rule: $p(x_1)=\int{p(x_1, x_2)dx_2}$
  - Product Rule: $p(x_1, x_2) = p(x_1)p(x_2|x_1) = p(x_2)p(x_1|x_2)$
  - Chain Rule: $p(x_1, x_2,...,x_p)=p(x_1)p(x_2|x_1)...p(x_p|x_1,x_2...,x_{p-1})$
  - Bayesian Rule: $p(x_1|x_2,...,x_p)=\frac{p(x_1)p(x_2,...,x_p|x_1)}{p(x_2,...,x_p)}=\frac{p(x_1)p(x_2,...,x_p|x_1)}{\int{p(x_1,x_2,...,x_p)dx_1}}$
- 计算规则的困境：维度高，计算量大
- 简化的核心：**变量之间相互独立**（最强的假设）
- 简化 1：**Naive Bayesian**（独立结构）
  - 条件独立性假设（条件概率相互独立）：$P(X|Y)=\prod_{i=1}^{p}P(x_i|Y)$
  - 劣势：假设过强
- 简化 2：**马尔可夫性** HMM（线性结构）
  - 齐次马尔可夫性假设（下一次状态与前几次都独立）：$x_j\perp x_{i+1}|x_i,j<i$
  - 观测独立性假设（观测结果只与状态相关）
  - 劣势：齐次马尔科夫性假设过强，当前状态经常与前几次相关
- 简化 3：条件随机场 CRF（图结构）
  - **条件独立性**：$x_A \perp{x_B} | x_C, x_{A,B,C}\ are\ groups\ with\ no\ intersection.$
  - 大大降低联合概率计算的复杂度。
- 概率图的四大问题：
  - 表示
    - 有向图 Bayesian Network
    - 无向图 Markov Network
  - 推断
    - 精确推断
    - 近似推断
  - 学习
    - 参数学习
    - 结构学习
  - 决策
